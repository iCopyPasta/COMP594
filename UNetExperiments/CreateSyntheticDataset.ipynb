{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will create 10 images\n",
      "rotations was true\n",
      "destination was /home/peo5032/Documents/COMP594/input/gen\n",
      "iteration was 10\n",
      "dimension chosen was 416\n",
      "scale ratio chosen was 0.05\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import argparse\n",
    "import DrawingWithTensors\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import torch\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "# initiate the parser\n",
    "parser = argparse.ArgumentParser(description = \"List of options to run application when creating custom datset\")\n",
    "\n",
    "parser = argparse.ArgumentParser()  \n",
    "parser.add_argument(\"-V\", \"--version\", help=\"show program version\", action=\"store_true\")\n",
    "parser.add_argument(\"-s\", \"--size\", help=\"upper bound of number of images to include\")\n",
    "parser.add_argument(\"-t\", \"--rotations\", help=\"allow random image and tensor rotations to be made\")\n",
    "parser.add_argument(\"-f\", \"--root_folder\", help=\"destination for root folder\")\n",
    "parser.add_argument(\"-g\", \"--generation\", help=\"which generation number we are using\")\n",
    "parser.add_argument(\"-d\", \"--dimensions\", help=\"square image dimensions\")\n",
    "parser.add_argument(\"-y\", \"--scale\", help=\"feet/pixel ratio\")\n",
    "\n",
    "#defined defaults\n",
    "upper_bound = 10\n",
    "isize = 416\n",
    "iteration = \"0\"\n",
    "rotations= False\n",
    "ROOT = \"/home/peo5032/Documents/COMP594/input/gen\"\n",
    "factor = 0.45\n",
    "\n",
    "# read arguments from the command line\n",
    "args = parser.parse_args(['-g','10',\n",
    "                          '-s','70000',\n",
    "                          '-d','416',\n",
    "                          '-t','true',\n",
    "                          '-f', '/home/peo5032/Documents/COMP594/input/gen',\n",
    "                          '-y', '0.05'\n",
    "                         ])\n",
    "\n",
    "# check for --version or -V\n",
    "if args.version:  \n",
    "    print(\"this is version 0.1\", flush=True)\n",
    "    \n",
    "if args.size: \n",
    "    print(\"will create\", upper_bound, \"images\", flush=True)\n",
    "    upper_bound = int(args.size) + 1\n",
    "\n",
    "if args.rotations: \n",
    "    rotations= args.rotations.lower() == \"true\"\n",
    "    print(\"rotations was\", args.rotations, flush=True)\n",
    "    \n",
    "if args.root_folder:  \n",
    "    os.makedirs(args.root_folder, exist_ok=True)\n",
    "    print(\"destination was\", args.root_folder, flush=True)\n",
    "    ROOT = args.root_folder\n",
    "    \n",
    "if args.generation:\n",
    "    print(\"iteration was\", args.generation, flush=True)\n",
    "    iteration = args.generation\n",
    "    \n",
    "if args.dimensions:\n",
    "    print(\"dimension chosen was\", args.dimensions,flush=True)\n",
    "    isize = int(args.dimensions)\n",
    "    \n",
    "if args.scale:\n",
    "    print(\"scale ratio chosen was\", args.scale,flush=True)\n",
    "    factor = args.scale\n",
    "    \n",
    "\n",
    "os.makedirs(ROOT, exist_ok=True)\n",
    "IMAGE_PATH = ROOT + iteration + \"/roads\"\n",
    "os.makedirs(IMAGE_PATH, exist_ok=True)\n",
    "\n",
    "TENSOR_PATH = ROOT + iteration + \"/tensor_values\"\n",
    "os.makedirs(TENSOR_PATH, exist_ok=True)\n",
    "\n",
    "PICKLE_PATH = ROOT + iteration\n",
    "\n",
    "df = pd.DataFrame()\n",
    "NumLanes = []\n",
    "ShldrWidth = []\n",
    "ShldrWidthCenter = []\n",
    "RoadWidth = []\n",
    "FileNames = []\n",
    "imageGen = DrawingWithTensors.datasetFactory(IMAGE_SIZE = isize)\n",
    "b_type = [\"trees\", \"water\", \"desert\"]\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pic 0/70001\n",
      "Pic 10/70001\n",
      "Pic 20/70001\n",
      "Pic 30/70001\n",
      "Pic 40/70001\n",
      "Pic 50/70001\n",
      "Pic 60/70001\n",
      "Pic 70/70001\n",
      "Pic 80/70001\n",
      "Pic 90/70001\n",
      "Pic 100/70001\n",
      "Pic 110/70001\n",
      "Pic 120/70001\n",
      "Pic 130/70001\n",
      "Pic 140/70001\n",
      "Pic 150/70001\n",
      "Pic 160/70001\n",
      "Pic 170/70001\n",
      "Pic 180/70001\n",
      "Pic 190/70001\n",
      "Pic 200/70001\n",
      "Pic 210/70001\n",
      "Pic 220/70001\n",
      "Pic 230/70001\n",
      "Pic 240/70001\n",
      "Pic 250/70001\n",
      "Pic 260/70001\n",
      "Pic 270/70001\n",
      "Pic 280/70001\n",
      "Pic 290/70001\n",
      "Pic 300/70001\n",
      "Pic 310/70001\n",
      "Pic 320/70001\n",
      "Pic 330/70001\n",
      "Pic 340/70001\n",
      "Pic 350/70001\n",
      "Pic 360/70001\n",
      "Pic 370/70001\n",
      "Pic 380/70001\n",
      "Pic 390/70001\n",
      "Pic 400/70001\n",
      "Pic 410/70001\n",
      "Pic 420/70001\n",
      "Pic 430/70001\n",
      "Pic 440/70001\n",
      "Pic 450/70001\n",
      "Pic 460/70001\n",
      "Pic 470/70001\n",
      "Pic 480/70001\n",
      "Pic 490/70001\n",
      "Pic 500/70001\n",
      "Pic 510/70001\n",
      "Pic 520/70001\n",
      "Pic 530/70001\n",
      "Pic 540/70001\n",
      "Pic 550/70001\n",
      "Pic 560/70001\n",
      "Pic 570/70001\n",
      "Pic 580/70001\n",
      "Pic 590/70001\n",
      "Pic 600/70001\n",
      "Pic 610/70001\n",
      "Pic 620/70001\n",
      "Pic 630/70001\n",
      "Pic 640/70001\n",
      "Pic 650/70001\n",
      "Pic 660/70001\n",
      "Pic 670/70001\n",
      "Pic 680/70001\n",
      "Pic 690/70001\n",
      "Pic 700/70001\n",
      "Pic 710/70001\n",
      "Pic 720/70001\n",
      "Pic 730/70001\n",
      "Pic 740/70001\n",
      "Pic 750/70001\n",
      "Pic 760/70001\n",
      "Pic 770/70001\n",
      "Pic 780/70001\n",
      "Pic 790/70001\n",
      "Pic 800/70001\n",
      "Pic 810/70001\n",
      "Pic 820/70001\n",
      "Pic 830/70001\n",
      "Pic 840/70001\n",
      "Pic 850/70001\n",
      "Pic 860/70001\n",
      "Pic 870/70001\n",
      "Pic 880/70001\n",
      "Pic 890/70001\n",
      "Pic 900/70001\n",
      "Pic 910/70001\n",
      "Pic 920/70001\n",
      "Pic 930/70001\n",
      "Pic 940/70001\n",
      "Pic 950/70001\n",
      "Pic 960/70001\n",
      "Pic 970/70001\n",
      "Pic 980/70001\n",
      "Pic 990/70001\n",
      "Pic 1000/70001\n",
      "Pic 1010/70001\n",
      "Pic 1020/70001\n",
      "Pic 1030/70001\n",
      "Pic 1040/70001\n",
      "Pic 1050/70001\n",
      "Pic 1060/70001\n",
      "Pic 1070/70001\n",
      "Pic 1080/70001\n",
      "Pic 1090/70001\n",
      "Pic 1100/70001\n",
      "Pic 1110/70001\n",
      "Pic 1120/70001\n",
      "Pic 1130/70001\n",
      "Pic 1140/70001\n",
      "Pic 1150/70001\n",
      "Pic 1160/70001\n",
      "Pic 1170/70001\n",
      "Pic 1180/70001\n",
      "Pic 1190/70001\n",
      "Pic 1200/70001\n",
      "Pic 1210/70001\n",
      "Pic 1220/70001\n",
      "Pic 1230/70001\n",
      "Pic 1240/70001\n",
      "Pic 1250/70001\n",
      "Pic 1260/70001\n",
      "Pic 1270/70001\n",
      "Pic 1280/70001\n",
      "Pic 1290/70001\n",
      "Pic 1300/70001\n",
      "Pic 1310/70001\n",
      "Pic 1320/70001\n",
      "Pic 1330/70001\n",
      "Pic 1340/70001\n",
      "Pic 1350/70001\n",
      "Pic 1360/70001\n",
      "Pic 1370/70001\n",
      "Pic 1380/70001\n",
      "Pic 1390/70001\n",
      "Pic 1400/70001\n",
      "Pic 1410/70001\n",
      "Pic 1420/70001\n",
      "Pic 1430/70001\n",
      "Pic 1440/70001\n",
      "Pic 1450/70001\n",
      "Pic 1460/70001\n",
      "Pic 1470/70001\n",
      "Pic 1480/70001\n",
      "Pic 1490/70001\n",
      "Pic 1500/70001\n",
      "Pic 1510/70001\n",
      "Pic 1520/70001\n",
      "Pic 1530/70001\n",
      "Pic 1540/70001\n",
      "Pic 1550/70001\n",
      "Pic 1560/70001\n",
      "Pic 1570/70001\n",
      "Pic 1580/70001\n",
      "Pic 1590/70001\n",
      "Pic 1600/70001\n",
      "Pic 1610/70001\n",
      "Pic 1620/70001\n",
      "Pic 1630/70001\n",
      "Pic 1640/70001\n",
      "Pic 1650/70001\n",
      "Pic 1660/70001\n",
      "Pic 1670/70001\n",
      "Pic 1680/70001\n",
      "Pic 1690/70001\n",
      "Pic 1700/70001\n",
      "Pic 1710/70001\n",
      "Pic 1720/70001\n",
      "Pic 1730/70001\n",
      "Pic 1740/70001\n",
      "Pic 1750/70001\n",
      "Pic 1760/70001\n",
      "Pic 1770/70001\n",
      "Pic 1780/70001\n",
      "Pic 1790/70001\n",
      "Pic 1800/70001\n",
      "Pic 1810/70001\n",
      "Pic 1820/70001\n",
      "Pic 1830/70001\n",
      "Pic 1840/70001\n",
      "Pic 1850/70001\n",
      "Pic 1860/70001\n",
      "Pic 1870/70001\n",
      "Pic 1880/70001\n",
      "Pic 1890/70001\n",
      "Pic 1900/70001\n",
      "Pic 1910/70001\n",
      "Pic 1920/70001\n",
      "Pic 1930/70001\n",
      "Pic 1940/70001\n",
      "Pic 1950/70001\n",
      "Pic 1960/70001\n",
      "Pic 1970/70001\n",
      "Pic 1980/70001\n",
      "Pic 1990/70001\n",
      "Pic 2000/70001\n",
      "Pic 2010/70001\n",
      "Pic 2020/70001\n",
      "Pic 2030/70001\n",
      "Pic 2040/70001\n",
      "Pic 2050/70001\n",
      "Pic 2060/70001\n",
      "Pic 2070/70001\n",
      "Pic 2080/70001\n",
      "Pic 2090/70001\n",
      "Pic 2100/70001\n",
      "Pic 2110/70001\n",
      "Pic 2120/70001\n",
      "Pic 2130/70001\n",
      "Pic 2140/70001\n",
      "Pic 2150/70001\n",
      "Pic 2160/70001\n",
      "Pic 2170/70001\n",
      "Pic 2180/70001\n",
      "Pic 2190/70001\n",
      "Pic 2200/70001\n",
      "Pic 2210/70001\n",
      "Pic 2220/70001\n",
      "Pic 2230/70001\n",
      "Pic 2240/70001\n",
      "Pic 2250/70001\n",
      "Pic 2260/70001\n",
      "Pic 2270/70001\n",
      "Pic 2280/70001\n",
      "Pic 2290/70001\n",
      "Pic 2300/70001\n",
      "Pic 2310/70001\n",
      "Pic 2320/70001\n",
      "Pic 2330/70001\n",
      "Pic 2340/70001\n",
      "Pic 2350/70001\n",
      "Pic 2360/70001\n",
      "Pic 2370/70001\n",
      "Pic 2380/70001\n",
      "Pic 2390/70001\n",
      "Pic 2400/70001\n",
      "Pic 2410/70001\n",
      "Pic 2420/70001\n",
      "Pic 2430/70001\n",
      "Pic 2440/70001\n",
      "Pic 2450/70001\n",
      "Pic 2460/70001\n",
      "Pic 2470/70001\n",
      "Pic 2480/70001\n",
      "Pic 2490/70001\n",
      "Pic 2500/70001\n",
      "Pic 2510/70001\n",
      "Pic 2520/70001\n",
      "Pic 2530/70001\n",
      "Pic 2540/70001\n",
      "Pic 2550/70001\n",
      "Pic 2560/70001\n",
      "Pic 2570/70001\n",
      "Pic 2580/70001\n",
      "Pic 2590/70001\n",
      "Pic 2600/70001\n",
      "Pic 2610/70001\n",
      "Pic 2620/70001\n",
      "Pic 2630/70001\n",
      "Pic 2640/70001\n",
      "Pic 2650/70001\n",
      "Pic 2660/70001\n",
      "Pic 2670/70001\n",
      "Pic 2680/70001\n",
      "Pic 2690/70001\n",
      "Pic 2700/70001\n",
      "Pic 2710/70001\n",
      "Pic 2720/70001\n",
      "Pic 2730/70001\n",
      "Pic 2740/70001\n",
      "Pic 2750/70001\n",
      "Pic 2760/70001\n",
      "Pic 2770/70001\n",
      "Pic 2780/70001\n",
      "Pic 2790/70001\n",
      "Pic 2800/70001\n",
      "Pic 2810/70001\n",
      "Pic 2820/70001\n",
      "Pic 2830/70001\n",
      "Pic 2840/70001\n",
      "Pic 2850/70001\n"
     ]
    }
   ],
   "source": [
    "tmp_tensor = torch.zeros(1,isize,isize,dtype=torch.float32)\n",
    "since = time.time()\n",
    "for i in range(0,upper_bound):\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(\"Pic {:0d}/{:0d}\".format(i,upper_bound), flush=True)\n",
    "    c = randint(0,80)\n",
    "    lanecount = randint(1,5)\n",
    "    laneWidth = randint(17,35)\n",
    "    lineWidth = randint(1,2)\n",
    "    shoulderWidth = randint(0,89)\n",
    "    \n",
    "    #create tuple of information, img, and tensor\n",
    "    tuple,img,tmp_tensor = imageGen.generateNewImageWithTensor(c,\n",
    "                                                               lanecount,\n",
    "                                                               laneWidth,\n",
    "                                                               lineWidth,\n",
    "                                                               shoulderWidth,\n",
    "                                                               tmp_tensor,\n",
    "                                                               b_type[randint(0,len(b_type)-1)],\n",
    "                                                               factor)\n",
    "    \n",
    "    roadWidth,laneCount,shoulderWidth,centerShldrWidth = tuple       \n",
    "    \n",
    "    if rotations:\n",
    "        img, tmp_tensor = DrawingWithTensors.rotationOfImageAndTensor(img,\n",
    "                                                                      tmp_tensor,\n",
    "                                                                      imageGen.classList,\n",
    "                                                                      randint(0,180),\n",
    "                                                                     )\n",
    "        \n",
    "    NumLanes.append(laneCount)\n",
    "    ShldrWidth.append(shoulderWidth)\n",
    "    RoadWidth.append (roadWidth)\n",
    "    ShldrWidthCenter.append(centerShldrWidth)\n",
    "    \n",
    "    FileName = str(i) + \".png\"\n",
    "    FileNames.append(FileName)\n",
    "    img.save(IMAGE_PATH + \"/\" + FileName,\"PNG\")\n",
    "    \n",
    "    #save tensor\n",
    "    torch.save(tmp_tensor, TENSOR_PATH + \"/\"+ str(i) + '.pt')\n",
    "    \n",
    "    img.close()\n",
    "    tmp_tensor = torch.mul(tmp_tensor, 0)\n",
    "\n",
    "df['NumLanes'] = NumLanes\n",
    "df['ShldrWidth'] = ShldrWidth\n",
    "df['RdwyWidth'] = RoadWidth\n",
    "df['ShldrWidthCenter'] = ShldrWidthCenter\n",
    "df['FileName'] = FileNames\n",
    "\n",
    "df.to_pickle(PICKLE_PATH + \"/train_images_v2.pkl\")\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Generation complete in {:.1f}m {:.1f}s'.format(time_elapsed // 60, time_elapsed % 60), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#testing output of data-set\n",
    "img = Image.open(IMAGE_PATH+\"/7.png\")\n",
    "test_tensor = torch.load(TENSOR_PATH+'/7.pt')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawingWithTensors.showInferenceOnImage(img, test_tensor, \"road\", 0.6, imageGen.classMap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
