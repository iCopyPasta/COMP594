{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# pytorch import and library calls\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# tensorflow imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_tensor = torch.Tensor([[1, 2], [3, 4]])\\ny_tensor = torch.Tensor([[5, 6], [7, 8]])\\n\\nx_variable = torch.autograd.Variable(x_tensor)\\n\\nprint(x_tensor * y_tensor)\\nprint(x_variable * 2)\\nprint(x_variable * y_tensor)\\nprint(((x_tensor + y_tensor))/4.0)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Reference of multiplication and operations of tensors in pytorch'''\n",
    "\n",
    "'''x_tensor = torch.Tensor([[1, 2], [3, 4]])\n",
    "y_tensor = torch.Tensor([[5, 6], [7, 8]])\n",
    "\n",
    "x_variable = torch.autograd.Variable(x_tensor)\n",
    "\n",
    "print(x_tensor * y_tensor)\n",
    "print(x_variable * 2)\n",
    "print(x_variable * y_tensor)\n",
    "print(((x_tensor + y_tensor))/4.0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 4\n",
    "imageSize = 256\n",
    "#transforms.RandomCrop(imageSize),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#transforms.ToTensor()\n",
    "#transforms.ToPILImage(),\n",
    "data_transform = transforms.Compose([transforms.Resize(imageSize),transforms.ToTensor()]\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for our GPU, otherwise, use a CPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else: \n",
    "    #SUN LAB AND NON-GPU PCs\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_FOLDER = '/home/peo5032/Documents/COMP594'\n",
    "NON_URBAN_DATA_FOLDER = '/home/peo5032/Documents/COMP594/NON_URBAN_IMAGES'\n",
    "URBAN_DATA_FOLDER = '/home/peo5032/Documents/COMP594/URBAN_IMAGES'\n",
    "\n",
    "\n",
    "ROOT_TEST_FOLDER = '/home/peo5032/Documents/COMP594_TEST'\n",
    "TEST_URBAN_DATA_FOLDER = '/home/peo5032/Documents/COMP594/URBAN_IMAGES'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_urban_dataset = datasets.ImageFolder(root=NON_URBAN_DATA_FOLDER ,\n",
    "#                                           transform=data_transform)\n",
    "\n",
    "urban_dataset = datasets.ImageFolder(root = ROOT_DATA_FOLDER, \n",
    "                                     transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(urban_dataset,\n",
    "                                             batch_size=batchSize, shuffle=True,\n",
    "                                             num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02).to(device=DEVICE)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02).to(device=DEVICE)\n",
    "        m.bias.data.fill_(0).to(device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 300, 10, 1, 0, bias = False),\n",
    "            nn.BatchNorm2d(300),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(300, 256, 10, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 10, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 256, 10, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 3, 10, 2, 1, bias = False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input.to(device=DEVICE))\n",
    "        return output.to(device=DEVICE)\n",
    "    \n",
    "netG = G().to(device=DEVICE)\n",
    "netG.apply(weights_init).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 256, 10, 2, 1, bias = False),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(256, 128, 10, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(128, 512, 10, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(512, 256, 10, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            nn.Conv2d(256, 1, 10, 1, 0, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input.to(device=DEVICE))\n",
    "        return output.view(-1).to(device=DEVICE)\n",
    "\n",
    "netD = D()\n",
    "netD.apply(weights_init).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "criterion = nn.BCELoss().to(device=DEVICE)\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "epochBound = 30\n",
    "\n",
    "for epoch in range(epochBound):\n",
    "\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        \n",
    "        netD.zero_grad()\n",
    "        \n",
    "        real, _ = data\n",
    "        input = Variable(real)\n",
    "        #print(\"INPUT IS:\", input)\n",
    "        target = Variable(torch.ones(input.size()[0]).to(device=DEVICE)).to(device=DEVICE)\n",
    "        #print(\"TAGET IS:\", target)\n",
    "        output = netD(input).to(device=DEVICE)\n",
    "        #print(\"OUTPUT IS:\", output)\n",
    "        #target = Variable(torch.ones(output.size()[0]))\n",
    "        errD_real = criterion(output, target).to(device=DEVICE)\n",
    "        \n",
    "        noise = Variable(torch.randn(input.size()[0], 100, 1, 1).to(device=DEVICE))\n",
    "        fake = netG(noise).to(device=DEVICE)\n",
    "        target = Variable(torch.zeros(input.size()[0]).to(device=DEVICE))\n",
    "        output = netD(fake.detach()).to(device=DEVICE)\n",
    "        errD_fake = criterion(output, target)\n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        netG.zero_grad()\n",
    "        target = Variable(torch.ones(input.size()[0]).to(device=DEVICE)).to(device=DEVICE)\n",
    "        output = netD(fake).to(device=DEVICE)\n",
    "        #arget = Variable(torch.ones(output.size()[0]))\n",
    "        errG = criterion(output, target)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, epochBound, i, len(data_loader), errD.data[0], errG.data[0]))\n",
    "        if i % 50 == 0:\n",
    "            vutils.save_image(real, '%s/real_samples.png' % \"./GANitR1\", normalize = True)\n",
    "            fake = netG(noise)\n",
    "            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % (\"./\", epoch), normalize = True)\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
